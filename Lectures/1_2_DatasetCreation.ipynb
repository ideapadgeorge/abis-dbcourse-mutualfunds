{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 1.2 : Clean & sub-set summary data\n",
    "## IDS : \n",
    "- CRSP_FUNDNO = sub-fund (share class) \n",
    "- CALDT = calendar date at quarter end\n",
    "\n",
    "## Objectives : \n",
    "1. Apply general filters to the whole dataset\n",
    "2. Subset the selected funds further to identify balanced, US active equity funds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from Functions import Utilis as Util\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apply Filters to Entire Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading & Describig files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Loading needed files...')\n",
    "t0 = time.time()\n",
    "fund_summary = pd.read_csv(inputPath + fund_summary_name, low_memory=False)\n",
    "CRSP_FUNDNO_WFICN = pd.read_csv(inputPath + CRSP_FUNDNO_WFICN_name, low_memory=False, encoding='latin1')\n",
    "FRONT_LOAD = pd.read_csv(inputPath + FRONT_LOAD_name, low_memory=False)\n",
    "REAR_LOAD = pd.read_csv(inputPath + REAR_LOAD_name, low_memory=False)\n",
    "t1 = time.time()\n",
    "print('Files were loaded in', t1-t0, 's!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('***DESCRIBING crsp_summary***')\n",
    "print('The shape of fund_summary is:', fund_summary.shape)\n",
    "print('-----.....-----.....-----')\n",
    "Util.isnull_chk(fund_summary, 'crsp_fundno')\n",
    "print('The number of unique crsp_fundno is:', fund_summary['crsp_fundno'].nunique())\n",
    "print('-----.....-----.....-----')\n",
    "Util.isnull_chk(fund_summary, 'crsp_cl_grp')\n",
    "print('The number of unique crsp_cl_grp is:', fund_summary['crsp_cl_grp'].nunique())\n",
    "print('-----.....-----.....-----')\n",
    "Util.isnull_chk(fund_summary, 'crsp_portno')\n",
    "print('The number of unique crsp_portno is:', fund_summary['crsp_portno'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('The average number of crsp_fundno per crsp_cl_grp per date:', \n",
    "      fund_summary.groupby(['crsp_cl_grp', 'caldt'])['crsp_fundno'].nunique().mean())\n",
    "print('The average number of crsp_fundno per crsp_cl_grp over time:', \n",
    "      fund_summary.groupby(['crsp_cl_grp'])['crsp_fundno'].nunique().mean())\n",
    "print('-----.....-----.....-----')\n",
    "print('The average number of crsp_portno per crsp_cl_grp per date:', \n",
    "      fund_summary.groupby(['crsp_cl_grp', 'caldt'])['crsp_portno'].nunique().mean())\n",
    "print('The average number of crsp_portno per crsp_cl_grp over time:', \n",
    "      fund_summary.groupby(['crsp_cl_grp'])['crsp_portno'].nunique().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fund_summary.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('***DESCRIBING CRSP_FUNDNO_WFICN***')\n",
    "print('The shape of CRSP_FUNDNO_WFICN is:', CRSP_FUNDNO_WFICN.shape)\n",
    "print('The columns of CRSP_FUNDNO_WFICN are:')\n",
    "print(CRSP_FUNDNO_WFICN.columns)\n",
    "CRSP_FUNDNO_WFICN.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('***DESCRIBING FRONT_LOAD***')\n",
    "print('The shape of FRONT_LOAD is:', FRONT_LOAD.shape)\n",
    "print('The columns of FRONT_LOAD are:') \n",
    "print(FRONT_LOAD.columns)\n",
    "FRONT_LOAD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('***DESCRIBING REAR_LOAD***')\n",
    "print('The shape of REAR_LOAD is:', REAR_LOAD.shape)\n",
    "print('The columns of REAR_LOAD are:')\n",
    "print(REAR_LOAD.columns)\n",
    "REAR_LOAD.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Converting data to correct type & transform dates to month end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Before:', type(fund_summary.caldt[0]), ' ', fund_summary.caldt[0])\n",
    "print('The unique dates of fund_summary are:')\n",
    "print(fund_summary.caldt.unique())\n",
    "print('The unique beddt of FRONT_LOAD are:')\n",
    "print(FRONT_LOAD.begdt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "print('Converting columns to the correct data types & transforming dates to monthend...')\n",
    "print('**This might take some time** -> Bonus points if you can do this more efficiently?')\n",
    "fund_summary.tna_latest = pd.to_numeric(fund_summary.tna_latest, errors='coerce') #invalid parsing will be set to NaN\n",
    "fund_summary_columns = list(fund_summary.columns)\n",
    "col_dt_list = [x for x in fund_summary_columns if x.endswith('dt')]\n",
    "for col in col_dt_list:\n",
    "    fund_summary[col] = pd.to_datetime(fund_summary[col])\n",
    "    fund_summary[col] = fund_summary[col].apply(lambda x: x + relativedelta(day=31))\n",
    "col_dt_list = [x for x in FRONT_LOAD if x.endswith('dt')]\n",
    "for col in col_dt_list:\n",
    "    FRONT_LOAD[col] = pd.to_datetime(FRONT_LOAD[col])\n",
    "    FRONT_LOAD[col] = FRONT_LOAD[col].apply(lambda x: x + relativedelta(day=31))\n",
    "    REAR_LOAD[col] = pd.to_datetime(REAR_LOAD[col])\n",
    "    REAR_LOAD[col] = REAR_LOAD[col].apply(lambda x: x + relativedelta(day=31))\n",
    "t1 = time.time()\n",
    "print('Columns have been converted in', t1-t0, 's!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('After:', type(fund_summary.caldt[0]), ' ', fund_summary.caldt[0])\n",
    "print('The unique dates of fund_summary are:')\n",
    "print(fund_summary.caldt.unique())\n",
    "print('The unique beddt of FRONT_LOAD are:')\n",
    "print(FRONT_LOAD.begdt.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Keeping only observations >= Dec 31st 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before')\n",
    "print('The mininum date in fund_summary is:', fund_summary.caldt.min())\n",
    "fund_summary = fund_summary.loc[fund_summary['caldt'] >= dt.datetime(1989, 12, 31)]\n",
    "print('After')\n",
    "print('The mininum date in fund_summary is:', fund_summary.caldt.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eliminating small funds: Keep if TNA_LATEST > 5 or TNA_LATEST is missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fundno_tna_latest_less5 = fund_summary.loc[fund_summary['tna_latest'] <= 5]['crsp_fundno']\n",
    "print('The total number of CRSP_FUNDNO is:', fund_summary.tna_latest.nunique())\n",
    "print('The number of CRSP_FUNDNO with TNA less than 5 is:', fundno_tna_latest_less5.nunique())\n",
    "print('The total number of observations is:', fund_summary.shape[0])\n",
    "print('The number of observations with TNA less than 5 is:', \n",
    "      fund_summary.loc[fund_summary['crsp_fundno'].isin(fundno_tna_latest_less5)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of Fund_Summary before eliminating small funds is:', fund_summary.shape)\n",
    "fund_summary['bad_obs'] = 0\n",
    "fund_summary.loc[fund_summary.tna_latest < 0, 'bad_obs'] = 1\n",
    "fund_summary.loc[fund_summary.tna_latest < 0, 'tna_latest'] = np.NaN\n",
    "fund_summary = fund_summary.loc[(fund_summary['tna_latest'].isnull()) | (fund_summary['tna_latest'] > 5)]\n",
    "print('The shape of Fund_Summary after eliminating small funds is:', fund_summary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adjusting for incubation bias: keep OBSERVATIONS (not funds) for which FIRST_OFFER_DT <= CALDT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of Fund_Summary before adjusting for incubation bias is:', fund_summary.shape[0])\n",
    "fund_summary = fund_summary.loc[(fund_summary['first_offer_dt'] <= fund_summary['caldt']) |\n",
    "                                (fund_summary['first_offer_dt'].isnull())]\n",
    "print('The shape of Fund_Summary after adjusting for incubation bias is:', fund_summary.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adjusting expenses, cash and fees for outliers s.t.\n",
    "- if [turn_ratio, exp_ratio, ACTUAL_12B1] = -99.00 then [turn_ratio, exp_ratio, ACTUAL_12B1] = np.nan\n",
    "- if ACTUAL_12B1 = 0 & CALDT < '01Jan1998'd then ACTUAL_12B1 = np.nan\n",
    "- Set the negative ACTUAL_12B1 values as missing values\n",
    "- if mgmt_fee < -50.00 then mgmt_fee = np.nan\n",
    "- if per_cash < -150.00 then per_cash = np.nan\n",
    "- if per_cash > 170.00 then per_cash = np.nan\n",
    "- if per_com == 999.99 then per_com = 99.999;\n",
    "- if per_com > 400 then per_com = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How do you pick these thresholds? \n",
    "- Understand the data!!\n",
    "1. Consult the manual: http://www.crsp.com/files/MFDB_Guide.pdf \n",
    "2. Use your common sense\n",
    "    - When you see a bunch of 99999 or -999999 it is probably a hard-coding for missing values\n",
    "    - Check variables distribution\n",
    "    - Manually check outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Adjusting variables...')\n",
    "fund_summary.loc[:, 'turn_ratio'] = [np.nan if x == -99 else x for x in fund_summary['turn_ratio']]\n",
    "fund_summary.loc[:, 'exp_ratio'] = [np.nan if x == -99 else x for x in fund_summary['exp_ratio']]\n",
    "fund_summary.loc[:, 'actual_12b1'] = [np.nan if x == -99 else x for x in fund_summary['actual_12b1']]\n",
    "fund_summary.loc[(fund_summary.actual_12b1 == 0) & (fund_summary.caldt < dt.datetime(1998, 1, 1)),'actual_12b1'] = np.nan\n",
    "fund_summary['actual_12b1'] = [np.nan if x < 0 else x for x in fund_summary['actual_12b1']]\n",
    "fund_summary.loc[:, 'mgmt_fee'] = [np.nan if x < -50 else x for x in fund_summary['mgmt_fee']]\n",
    "fund_summary.loc[:, 'per_cash'] = [np.nan if ((x < -150) or (x > 170)) else x for x in fund_summary['per_cash']]\n",
    "fund_summary.loc[:, 'per_com'] = [99.999 if x == 999.99 else x for x in fund_summary['per_com']]\n",
    "fund_summary.loc[:, 'per_com'] = [np.nan if x > 400 else x for x in fund_summary['per_com']]\n",
    "print('Variables were adjusted!')\n",
    "print('Number of observations having negative exp_ratio', sum(fund_summary['exp_ratio'] < 0))\n",
    "print('Number of observations having negative ACTUAL_12B1', sum(fund_summary['actual_12b1'] < 0))\n",
    "print('Number of observations having negative mgmt_fee', sum(fund_summary['mgmt_fee'] < 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Does it make sense to have negarive mgmt_fee?\n",
    "- Instinctively you would probably say no BUT\n",
    "- Consult the manual first: http://www.crsp.com/files/MFDB_Guide.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adding information about loads from separate file\n",
    "Load = rear_load + front_load\n",
    "Before doing that though, you need to:\n",
    "1. Adjust for outliers : \n",
    "    - if REAR_LOAD = -99 then REAR_LOAD = np.nan \n",
    "    - if FRONT_LOAD = -99 then FRONT_LOAD = np.nan;\n",
    "2. Adjust the begin and end dates to monthend (BEGDT, ENDDT)\n",
    "3. Fill information forward at the monthly frequency\n",
    "4. For each fund/month observation take the average of all available front_loads and read_loads\n",
    "    - Different share classes might have different loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Setting -99 values to missing') \n",
    "FRONT_LOAD['front_load'] = [np.nan if x == -99 else x for x in FRONT_LOAD['front_load']]\n",
    "FRONT_LOAD.loc[FRONT_LOAD['front_load'].isnull(), 'front_load'] = 0\n",
    "REAR_LOAD['rear_load'] = [np.nan if x == -99 else x for x in REAR_LOAD['rear_load']]\n",
    "REAR_LOAD.loc[REAR_LOAD['rear_load'].isnull(), 'rear_load'] = 0\n",
    "FRONT_LOAD['front_load'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if printing:\n",
    "    print('Expanding FRONT LOADS...')\n",
    "    print('This will also take some time -> Bonus points is you can improve this?')    \n",
    "FRONT_LOAD['index'] = FRONT_LOAD.index\n",
    "t0 = time.time()\n",
    "frontload_expand_dict = {}\n",
    "for i in range(len(FRONT_LOAD)):\n",
    "    start = FRONT_LOAD['begdt'][i]\n",
    "    end = FRONT_LOAD['enddt'][i]\n",
    "    frontload_expand_dict[i] = [Util.last_day_of_month(dt.date(m//12, m%12+1, 1)) \n",
    "                                for m in range(start.year*12+start.month-1, end.year*12+end.month)]\n",
    "df = pd.DataFrame(pd.Series(frontload_expand_dict, name='date'), columns=['date'])\n",
    "df2 = pd.DataFrame(pd.DataFrame(df.date.values.tolist(), index= df.index).stack()).reset_index()\n",
    "df2 = df2.drop(['level_1'], axis = 1)\n",
    "df2.columns = ['index', 'date']\n",
    "FRONT_LOAD2 = pd.merge(FRONT_LOAD, df2, on = 'index', how = 'outer')\n",
    "FRONT_LOAD2 = FRONT_LOAD2.drop(['index'], axis = 1)\n",
    "del df\n",
    "del df2\n",
    "t1 = time.time()\n",
    "print('Finished Expanding Front Loads in:', t1-t0, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Expanding REAR LOADS...')\n",
    "print('Same as above, this will also take some time...')\n",
    "REAR_LOAD['index'] = REAR_LOAD.index\n",
    "t0 = time.time()\n",
    "rearload_expand_dict = {}\n",
    "for i in range(len(REAR_LOAD)):\n",
    "    start = REAR_LOAD['begdt'][i]\n",
    "    end = REAR_LOAD['enddt'][i]\n",
    "    rearload_expand_dict[i] = [Util.last_day_of_month(dt.date(m//12, m%12+1, 1)) \n",
    "                                for m in range(start.year*12+start.month-1, end.year*12+end.month)]\n",
    "df = pd.DataFrame(pd.Series(rearload_expand_dict, name='date'), columns=['date'])\n",
    "df2 = pd.DataFrame(pd.DataFrame(df.date.values.tolist(), index= df.index).stack()).reset_index()\n",
    "df2 = df2.drop(['level_1'], axis = 1)\n",
    "df2.columns = ['index', 'date']\n",
    "REAR_LOAD2 = pd.merge(REAR_LOAD, df2, on = 'index', how = 'outer')\n",
    "REAR_LOAD2 = REAR_LOAD2.drop(['index'], axis = 1)\n",
    "del df\n",
    "del df2\n",
    "t1 = time.time()\n",
    "print('Finished Expanding Rear Loads in:', t1-t0, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Checking output...')\n",
    "FRONT_LOAD = FRONT_LOAD.sort_values(['crsp_fundno', 'begdt', 'enddt'])\n",
    "FRONT_LOAD2 = FRONT_LOAD2.sort_values(['crsp_fundno', 'date'])\n",
    "print('Shape before expansion:', FRONT_LOAD.shape)\n",
    "print('Shape after expansion:', FRONT_LOAD2.shape)\n",
    "print(FRONT_LOAD2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Taking the average of front and end loads by fund-monthend...')\n",
    "print('This takes even longer to run!! Can you thing of an entirely different way of doing this?')\n",
    "t0 = time.time()\n",
    "agg_FRONT_LOAD = FRONT_LOAD2.groupby(['crsp_fundno', 'date'])[['front_load']].apply(np.mean).reset_index()\n",
    "agg_REAR_LOAD = REAR_LOAD2.groupby(['crsp_fundno', 'date'])[['rear_load']].apply(np.mean).reset_index()\n",
    "agg_LOADs = pd.merge(agg_FRONT_LOAD, agg_REAR_LOAD, left_on=['crsp_fundno', 'date'], how='outer',right_on=['crsp_fundno', 'date'])\n",
    "agg_LOADs.loc[agg_LOADs['rear_load'].isnull(), 'rear_load'] = 0\n",
    "agg_LOADs.loc[agg_LOADs['front_load'].isnull(), 'front_load'] = 0\n",
    "agg_LOADs['load'] = agg_LOADs['front_load'] + agg_LOADs['rear_load']\n",
    "agg_LOADs.rename(columns={'date': 'caldt'}, inplace=True)\n",
    "agg_LOADs.caldt = pd.to_datetime(agg_LOADs.caldt)\n",
    "t1 = time.time()\n",
    "print('Averaging completed in', t1-t0, 's')\n",
    "print(agg_LOADs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Merging aggregate loads to full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of Fund_Summary before adding loads is:', fund_summary.shape[0])\n",
    "fund_summary = pd.merge(fund_summary, agg_LOADs, left_on=['crsp_fundno', 'caldt'], how='left',right_on=['crsp_fundno', 'caldt'])\n",
    "print('The shape of Fund_Summary after adding loads is:', fund_summary.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Merge the WFICN identifier by CRSP_FUNDNO using the Mflinks_crsp dataset on WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "CRSP_FUNDNO_WFICN.wficn = CRSP_FUNDNO_WFICN.wficn.apply(lambda x: int(x))\n",
    "ids = CRSP_FUNDNO_WFICN['crsp_fundno']\n",
    "print('The number of CRSP_FUNDNOs having multiple WFICN is:', CRSP_FUNDNO_WFICN[ids.isin(ids[ids.duplicated()])].shape[0])\n",
    "print('Dropping duplicates...')\n",
    "print('Can you do any better than just dropping duplicates??')\n",
    "CRSP_FUNDNO_WFICN = CRSP_FUNDNO_WFICN[['crsp_fundno', 'wficn']]\n",
    "CRSP_FUNDNO_WFICN = CRSP_FUNDNO_WFICN.drop_duplicates(subset=['crsp_fundno'], keep='first')\n",
    "print('Duplicates dropped! Merging to fund summary...')\n",
    "print('The shape of Fund_Summary before merging WFICN is: ', str(fund_summary.shape))\n",
    "fund_summary = pd.merge(fund_summary, CRSP_FUNDNO_WFICN, on='crsp_fundno', how='left')\n",
    "print('The shape of Fund_Summary after merging WFICN is: ', str(fund_summary.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset after applying generic filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of fund_summary is:', fund_summary.shape)\n",
    "fund_summary.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subset the data to US Active Equity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Subsetting according to the CRSP_OBJ_CD: \n",
    "- First digit: Equity (E)\n",
    "- Second digit: Domestic (D) \n",
    "- Third digit: Non-Sector (so either C or Y NOT S)\n",
    "- Fourth digit: all possible 4th digits\n",
    "\n",
    "**Check color coded map at the end of the manual: http://www.crsp.com/files/MFDB_Guide.pdf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('The number of observations in Fund_Summary before subsetting is:', fund_summary.shape[0])\n",
    "con1 = [str(x).startswith('EDC') for x in fund_summary['crsp_obj_cd']]\n",
    "con2 = [str(x).startswith('EDY') for x in fund_summary['crsp_obj_cd']]\n",
    "con = [x or y for x, y in zip(con1, con2)]\n",
    "fund_summary_US_Active = fund_summary.loc[con]\n",
    "print('The number of observations in Fund_Summary after subsetting is:', fund_summary_US_Active.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subsetting according to Lipper, Strategic insight and Wiesenberger codes as follows:\n",
    "- indicator = 0;\n",
    "- if LIPPER_OBJ_CD = 'SP' or LIPPER_OBJ_CD = 'MC' or LIPPER_OBJ_CD = 'SG' or LIPPER_OBJ_CD = 'MR' or \n",
    "     LIPPER_OBJ_CD = 'CA' or LIPPER_OBJ_CD = 'G' or LIPPER_OBJ_CD = 'GI' or LIPPER_OBJ_CD = 'LSE' or \n",
    "     LIPPER_OBJ_CD = 'EMN' or LIPPER_OBJ_CD = 'ABR' or LIPPER_OBJ_CD = 'DL' or LIPPER_OBJ_CD = 'EI' then indicator = 1 \n",
    "- if LIPPER_OBJ_CD = \"\" and (SI_OBJ_CD = 'GMC' or SI_OBJ_CD = 'SCG' or SI_OBJ_CD = 'AGG' or SI_OBJ_CD = 'GRO' \n",
    "     or SI_OBJ_CD = 'GRI' or SI_OBJ_CD = 'ING' or SI_OBJ_CD = 'OPI') then indicator = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- if LIPPER_OBJ_CD = \"\" and SI_OBJ_CD = \"\" and (WBRGER_OBJ_CD = 'SGC' or WBRGER_OBJ_CD = 'G' or \n",
    "     WBRGER_OBJ_CD = 'LTG' or WBRGER_OBJ_CD = 'MCG' or WBRGER_OBJ_CD = 'GCI' or WBRGER_OBJ_CD = 'IEQ') \n",
    "     then indicator = 1\n",
    "- if LIPPER_OBJ_CD = \"\" and SI_OBJ_CD = \"\" and WBRGER_OBJ_CD = \"\" and POLICY = 'CS' then indicator = 1\n",
    "- if indicator = 1 then KEEP\n",
    "- if CRSP_OBJ_CD = 'EDS' or CRSP_OBJ_CD = 'EDSU' or CRSP_OBJ_CD = 'EDYI' or CRSP_OBJ_CD = 'EDYS' then DELETE\n",
    "- if WBRGER_OBJ_CD = 'BAL' or WBRGER_OBJ_CD = 'IFL' then DELETE\n",
    "- if CRSP_OBJ_CD = \"\" and LIPPER_OBJ_CD = \"\" and SI_OBJ_CD = \"\" and WBRGER_OBJ_CD = \"\" and POLICY = \"\" \n",
    "     then DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('The number of observations in Fund_Summary before subsetting is:', fund_summary_US_Active.shape[0])\n",
    "LIPPER_OBJ_CD = [\"MC\", 'SG', 'MR', 'CA', 'G', 'GI', 'LSE', 'EMN', 'ABR', 'DL', 'EI']\n",
    "con1 = fund_summary_US_Active['lipper_obj_cd'].isin(LIPPER_OBJ_CD)\n",
    "SI_OBJ_CD = ['GMC', 'SCG', 'AGG', 'GRO', 'GRI', 'ING', 'OPI']\n",
    "con2 = fund_summary_US_Active['lipper_obj_cd'].isnull() & fund_summary_US_Active['si_obj_cd'].isin(SI_OBJ_CD)\n",
    "WBRGER_OBJ_CD = ['SGC', 'G', 'LTG', 'MCG', 'GCI', 'IEQ']\n",
    "con3 = fund_summary_US_Active['lipper_obj_cd'].isnull() & fund_summary_US_Active['si_obj_cd'].isnull() & \\\n",
    "        fund_summary_US_Active['wbrger_obj_cd'].isin(WBRGER_OBJ_CD)\n",
    "con4 = fund_summary_US_Active['lipper_obj_cd'].isnull() & fund_summary_US_Active['si_obj_cd'].isnull() & \\\n",
    "           fund_summary_US_Active['wbrger_obj_cd'].isnull() & fund_summary_US_Active['policy'].isin(['CS'])\n",
    "fund_summary_US_Active = fund_summary_US_Active.loc[con1 | con2 | con3 | con4]\n",
    "drop_list_WBRGER_OBJ_CD = ['BAL', 'IFL']\n",
    "con5 = fund_summary_US_Active['wbrger_obj_cd'].isin(drop_list_WBRGER_OBJ_CD)\n",
    "con6 = fund_summary_US_Active['lipper_obj_cd'].isnull() & fund_summary_US_Active['si_obj_cd'].isnull() & \\\n",
    "           fund_summary_US_Active['wbrger_obj_cd'].isnull() & fund_summary_US_Active['policy'].isnull()\n",
    "fund_summary_US_Active = fund_summary_US_Active.loc[~con5 & ~con6]\n",
    "print('The number of observations in Fund_Summary after subsetting is:', fund_summary_US_Active.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Excluding index funds: \n",
    "- funds with INDEX_FUND_FLAG = ‘D’;\n",
    "- funds which contain any of the following in their names:\n",
    "    - ‘Index’, ‘Ind’, ‘Idx’, ‘Indx’, ‘iShares’, ‘SPDR’, ‘HOLDRs’, ‘ETF’, ‘Exchange-Traded Fund’, ‘PowerShares’,‘StreetTRACKS’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Keeping funds with INDEX_FUND_FLAG = D...')\n",
    "print('The number of observations in Fund_Summary before subsetting is:', fund_summary_US_Active.shape[0])\n",
    "fund_summary_US_Active = fund_summary_US_Active.loc[fund_summary_US_Active['index_fund_flag'] != 'D']\n",
    "print('The number of observations in Fund_Summary after subsetting is:', fund_summary_US_Active.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Removing funds with index related words in the name (list in settings)...')\n",
    "print('The number of observations in Fund_Summary before subsetting is:', fund_summary_US_Active.shape[0])\n",
    "for content in eliminated_content:\n",
    "    fund_summary_US_Active = fund_summary_US_Active.loc[\n",
    "        ~fund_summary_US_Active['fund_name'].str.lower().str.contains(content.lower(), na=False)]\n",
    "print('The number of observations in Fund_Summary after subsetting is:', fund_summary_US_Active.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Keeping only open ended funds: if ET_FLAG = 'F' or ET_FLAG = 'N' then DELETE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The number of observations in Fund_Summary before subsetting is:', fund_summary_US_Active.shape[0])\n",
    "fund_summary_US_Active = fund_summary_US_Active.loc[fund_summary_US_Active['et_flag'] != 'F']\n",
    "fund_summary_US_Active = fund_summary_US_Active.loc[fund_summary_US_Active['et_flag'] != 'N']\n",
    "print('The number of observations in Fund_Summary after subsetting is:', fund_summary_US_Active.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eliminating observations with no fund_name, crsp_cl_grp and wficn...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of Fund_Summary before eliminating observations with no crsp_fundno, fund_name, crsp_cl_grp & wficn is:')\n",
    "con7 = fund_summary_US_Active.fund_name.isnull() & fund_summary_US_Active.crsp_cl_grp.isnull() & \\\n",
    "        fund_summary_US_Active.wficn.isnull()\n",
    "fund_summary_US_Active = fund_summary_US_Active[~con7]\n",
    "print('The shape of Fund_Summary after eliminating observations with no crsp_fundno, fund_name, crsp_cl_grp & wficn is:')\n",
    "print(fund_summary_US_Active.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eliminating Variable Annuity Underlying Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of Fund_Summary before eliminating Variable Annuity Underlying funds is:', fund_summary_US_Active.shape)\n",
    "print('Before elimination, the frequency of Variable Annuity (Y) funds vs. the rest (N) is:')\n",
    "print(fund_summary_US_Active['vau_fund'].value_counts())\n",
    "fund_summary_US_Active = fund_summary_US_Active[fund_summary_US_Active.vau_fund != 'Y']\n",
    "fund_summary_US_Active.drop(['vau_fund'], axis=1, inplace=True)\n",
    "print('The shape of Fund_Summary after eliminating Variable Annuity Underlying funds is:', fund_summary_US_Active.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardize Names: \n",
    "- Separate original fund_name to group_name + fund_name_short + share_class, and save the original fund_name as fund_name_long\n",
    "- share_class: \n",
    "    - anything after the last ';' or '/' or ',' or ':' or '\\'\n",
    "    - anything after the word 'class'\n",
    "    - some special case\n",
    "- group_name: anything before the first ':'\n",
    "- fund_name_short: the original fund_name apart from group_name and share_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Separating Fund Names from Group Names and Share Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('An example:')\n",
    "print(fund_summary_US_Active.fund_name.iloc[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Getting the sub-parts of the fund names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fund_summary_US_Active.rename(index=str, columns={\"fund_name\": \"fund_name_long\"}, inplace=True)\n",
    "fund_summary_US_Active['share_class'] = fund_summary_US_Active.fund_name_long.apply(Util.get_share_class)\n",
    "fund_summary_US_Active['fund_name_short'] = fund_summary_US_Active.fund_name_long.apply(Util.get_short_fundname)\n",
    "fund_summary_US_Active['group_name'] = fund_summary_US_Active.fund_name_short.apply(Util.get_group_name)\n",
    "fund_summary_US_Active['fund_name_short'] = fund_summary_US_Active.fund_name_short.apply(Util.update_short_fundname)\n",
    "print('An example continued...')\n",
    "fund_summary_US_Active[['group_name', 'share_class', 'fund_name_short', 'fund_name_long']].iloc[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Handling naming exceptions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fund_summary_US_Active['group_name'] = fund_summary_US_Active.group_name.apply(Util.correct_name, \n",
    "                                                                               exceptions=exceptions, retNaN=False)\n",
    "fund_summary_US_Active.loc[(fund_summary_US_Active.group_name == \"Voyageur Mutual Funds III\") &\n",
    "                               (fund_summary_US_Active.caldt > dt.datetime(2002, 6, 25)) &\n",
    "                               (fund_summary_US_Active.caldt <= dt.datetime(2009, 1, 8)), \n",
    "                           'group_name'] = \"voyageur mutual funds iii mn\"\n",
    "print('Corrections completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use Fund_name's group part to fill in crsp_cl_grp\n",
    "#### Check how many observations don’t have CRSP_CL_GRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Util.isnull_chk(fund_summary_US_Active, 'crsp_cl_grp')\n",
    "print('-----.....-----.....')\n",
    "print('Before August 13 1998 - first date of validity of crsp_cl_grp:')\n",
    "a = fund_summary_US_Active[fund_summary_US_Active.caldt <= dt.datetime(1998, 8, 31)]\n",
    "Util.isnull_chk(a, 'crsp_cl_grp')\n",
    "b = a[(a.wficn.isnull()) & (a.wficn.isnull())]\n",
    "print('Of which the ones that that don\\'t have both crsp_cl_grp and wficn are:', b.shape[0])\n",
    "print('The number of observations not having crsp_cl_grp & group_name is:', \n",
    "     fund_summary_US_Active.loc[\n",
    "            (fund_summary_US_Active['crsp_cl_grp'].isnull()) &\n",
    "            (fund_summary_US_Active['group_name'].isnull())].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eliminate observations that don't have a caldt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape fund_summary_US_Active before eliminating observations with no caldt is:', fund_summary_US_Active.shape)\n",
    "fund_summary_US_Active = fund_summary_US_Active[~fund_summary_US_Active.caldt.isnull()]\n",
    "print('The shape fund_summary_US_Active after eliminating observations with no caldt is:', fund_summary_US_Active.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check uniqness of fund_name & group_name for grp/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Checking uniqness of fund_name & group_name for grp/month...\")\n",
    "for col in ['fund_name_short', 'group_name']:\n",
    "    non_unique = fund_summary_US_Active.groupby(['crsp_cl_grp', 'caldt'])[col].nunique()\n",
    "    non_existing = fund_summary_US_Active[fund_summary_US_Active[col].isnull()].drop_duplicates(subset=[\n",
    "        'crsp_cl_grp', 'caldt'])\n",
    "    print('Number of grp/month having multiple', col, ': ', sum(non_unique > 1))\n",
    "    print('Number of grp/month not having', col, ': ', len(non_existing))\n",
    "    if sum(non_unique > 1) > 0:\n",
    "        multi_fundname = pd.DataFrame()\n",
    "        index = list(non_unique[non_unique > 1].index)\n",
    "        for i in index:\n",
    "            multi_fundname = pd.concat([multi_fundname,\n",
    "                                        fund_summary_US_Active.loc[(fund_summary_US_Active['crsp_cl_grp'] == i[0])\n",
    "                                                                   & (fund_summary_US_Active['caldt'] == i[1]),\n",
    "                                                                   ['crsp_fundno',  'crsp_cl_grp', 'caldt',\n",
    "                                                                    'fund_name_short', 'fund_name_long']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset summary: Providing a description of the final dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The number of crsp_fundno present is:', len(fund_summary_US_Active.crsp_fundno.unique()))\n",
    "print('The number of crsp_portnos present is:', len(fund_summary_US_Active.crsp_portno.unique()))\n",
    "print('The number of crsp_cl_grp present is:', len(fund_summary_US_Active.crsp_cl_grp.unique()))\n",
    "print('The number of wficn present is:', len(fund_summary_US_Active.wficn.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Frequency of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['crsp_obj_cd', 'lipper_obj_cd']\n",
    "for col in categorical_variables:\n",
    "    print('Frequency of', col, 'in fund_summary_US_Active:')\n",
    "    print(fund_summary_US_Active.drop_duplicates('crsp_cl_grp')[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Saving the cleaned Active Equity dataset to file...\")\n",
    "fund_summary_US_Active.to_csv(outputPath + fund_summary_ActiveEq_name, index=False)\n",
    "print('File saved!')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
